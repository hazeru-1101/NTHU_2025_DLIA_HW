{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "609dcb62-c2f8-4c6d-9c89-63dc0148a87c"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "###### Lab 2\n",
    "\n",
    "# National Tsing Hua University\n",
    "\n",
    "#### Spring 2025\n",
    "\n",
    "#### 11320IEEM 513600\n",
    "\n",
    "#### Deep Learning and Industrial Applications\n",
    "    \n",
    "## Lab 2: Predicting Heart Disease with Deep Learning\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "061c22d2-eec4-40f4-866b-ccaa2d9a2963",
    "tags": []
   },
   "source": [
    "### Introduction\n",
    "\n",
    "In the realm of healthcare, early detection and accurate prediction of diseases play a crucial role in patient care and management. Heart disease remains one of the leading causes of mortality worldwide, making the development of effective diagnostic tools essential. This lab leverages deep learning to predict the presence of heart disease in patients using a subset of 14 key attributes from the Cleveland Heart Disease Database. The objective is to explore and apply deep learning techniques to distinguish between the presence and absence of heart disease based on clinical parameters.\n",
    "\n",
    "Throughout this lab, you'll engage with the following key activities:\n",
    "- Use [Pandas](https://pandas.pydata.org) to process the CSV files.\n",
    "- Use [PyTorch](https://pytorch.org) to build an Artificial Neural Network (ANN) to fit the dataset.\n",
    "- Evaluate the performance of the trained model to understand its accuracy.\n",
    "\n",
    "### Attribute Information\n",
    "\n",
    "1. age: Age of the patient in years\n",
    "2. sex: (Male/Female)\n",
    "3. cp: Chest pain type (4 types: low, medium, high, and severe)\n",
    "4. trestbps: Resting blood pressure\n",
    "5. chol: Serum cholesterol in mg/dl\n",
    "6. fbs: Fasting blood sugar > 120 mg/dl\n",
    "7. restecg: Resting electrocardiographic results (values 0,1,2)\n",
    "8. thalach: Maximum heart rate achieved\n",
    "9. exang: Exercise induced angina\n",
    "10. oldpeak: Oldpeak = ST depression induced by exercise relative to rest\n",
    "11. slope: The slope of the peak exercise ST segment\n",
    "12. ca: Number of major vessels (0-3) colored by fluoroscopy\n",
    "13. thal: 3 = normal; 6 = fixed defect; 7 = reversible defect\n",
    "14. target: target have disease or not (1=yes, 0=no)\n",
    "\n",
    "### References\n",
    "- [UCI Heart Disease Data](https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data) for the dataset we use in this lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "ad594fc8-4989-40f3-b124-4550fe7df386"
   },
   "source": [
    "## A. Checking and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23855,
     "status": "ok",
     "timestamp": 1742826990476,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "pfITSFq7skol",
    "outputId": "e7900e3c-595a-446f-c4a1-c63805acef2f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 910,
     "status": "ok",
     "timestamp": 1742827063023,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "42a3eafd-cbcd-4c56-82cb-83a0bfa2399e",
    "outputId": "5734f92a-375b-4866-96fe-91e4087e7564"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/content/drive/MyDrive/深度學習/heart_dataset_train_all.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742827065711,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "34241797-60f0-4818-a44b-f5379948d621",
    "outputId": "161159bc-5a4e-4069-c791-16c8b987c843"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742827067260,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "026585db-a6d8-4062-85de-e3a7eaebed72",
    "outputId": "9d606df8-482f-4aca-c91c-9d6eb3ef740f"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742827069897,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "69031e6d-0fb5-49d9-b723-a0d1fee08c3c",
    "outputId": "63ee10f4-9b2f-4f50-c0e1-33508ea15b8a"
   },
   "outputs": [],
   "source": [
    "# checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742827070818,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "cb3090f8-2cfa-4f56-8aa5-cf954bb19932"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742827071094,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "38aadbee-d68f-4ae0-b842-b40800b0cac9",
    "outputId": "ff9094da-e723-4ad7-fd79-a66d09eb319e"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1742827071633,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "26a69fd5-3534-4d8e-b59a-6778bf47a479",
    "outputId": "ee8c2cf6-efe4-4131-910c-d0bf9b9c9b1d"
   },
   "outputs": [],
   "source": [
    "# Mapping 'sex' descriptions to numbers\n",
    "sex_description = {\n",
    "    'Male': 0,\n",
    "    'Female': 1,\n",
    "}\n",
    "df.loc[:, 'sex'] = df['sex'].map(sex_description)\n",
    "\n",
    "# Mapping 'cp' (chest pain) descriptions to numbers\n",
    "pain_description = {\n",
    "    'low': 0,\n",
    "    'medium': 1,\n",
    "    'high': 2,\n",
    "    'severe': 3\n",
    "}\n",
    "df.loc[:, 'cp'] = df['cp'].map(pain_description)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1742827073168,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "051108c6-7011-4187-9e36-bd2944a019ca",
    "outputId": "eef73bc8-114b-424b-a6b9-4fc496f30a3b"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1742827074391,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "8b999df5-09a1-4ce2-b068-f1afba448ff8",
    "outputId": "f3c7565e-5543-4df1-fee7-2219107a1cf2"
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "8ce7a0c5-76d6-4863-ba61-0544a220962a"
   },
   "source": [
    "#### Converting the DataFrame to a NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1742827076634,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "5735baad-2db8-4306-aa4c-7788d2b49621",
    "outputId": "50ba9a83-032b-428c-a951-31faf11e4ce4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_data = df.values\n",
    "np_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1742827077438,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "29b8e189-7f39-435a-8038-39098b147325"
   },
   "outputs": [],
   "source": [
    "split_point = int(np_data.shape[0]*0.7)\n",
    "\n",
    "np.random.shuffle(np_data)\n",
    "\n",
    "x_train = np_data[:split_point, :13]\n",
    "y_train = np_data[:split_point, 13]\n",
    "x_val = np_data[split_point:, :13]\n",
    "y_val = np_data[split_point:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3852,
     "status": "ok",
     "timestamp": 1742827082171,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "fedb56d7-1665-4c90-9697-b86cab43f300",
    "outputId": "44b4cad8-d89c-41df-9c7f-a32a98a941c8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train = np.array(x_train, dtype=float)\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = np.array(y_train, dtype=int)\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "\n",
    "x_val = np.array(x_val, dtype=float)\n",
    "x_val = torch.from_numpy(x_val).float()\n",
    "y_val = np.array(y_val, dtype=int)\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Number of samples in train and validation are {len(train_loader.dataset)} and {len(val_loader.dataset)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "id": "8ffc26b9-6044-41e9-93e2-7dc6250dbd27"
   },
   "source": [
    "## B. Defining Neural Networks\n",
    "\n",
    "In PyTorch, we can use **class** to define our custom neural network architectures by subclassing the `nn.Module` class. This gives our neural network all the functionality it needs to work with PyTorch's other utilities and keeps our implementation organized.\n",
    "\n",
    "- Neural networks are defined by subclassing `nn.Module`.\n",
    "- The layers of the neural network are initialized in the `__init__` method.\n",
    "- The forward pass operations on input data are defined in the `forward` method.\n",
    "\n",
    "It's worth noting that while we only define the forward pass, PyTorch will automatically derive the backward pass for us, which is used during training to update the model's weights.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742827085782,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "77975746-a7a7-4676-9527-57674cd98c0f"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(13, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2)\n",
    "        ).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "cbb8b5b0-0ec0-406c-a42e-048aa00e05aa"
   },
   "source": [
    "## C. Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1742827087257,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "3602ae7d-4034-4c49-b221-0c12a5824b18",
    "outputId": "ecb749e1-ed5f-4120-fa60-da73804a78bc"
   },
   "outputs": [],
   "source": [
    "# Check your GPU status.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "db148a2913234db0abcfc1eca9844dbc",
      "6b818769b204436884e6221921df7388",
      "ae6a4a0fb68f407db8508d8f27e43338",
      "dd552bfa14214d6ba597504dcd206cb7",
      "19a468856b7f4f56a3aed753e0e0c2c6",
      "49db8ab44ea74fdb96ad0a45c5982aa4",
      "1c3a31d5eb1f43679d00fbff4457d3a9",
      "a4322342c75a4a92aa291fea5cb019b0",
      "8652c6cb9c334376a80909713bf48801",
      "214f971f1e9b437d8f1c123a1a2e16f8",
      "435c5a503f884600b73faab1b92b1435"
     ]
    },
    "executionInfo": {
     "elapsed": 7034,
     "status": "ok",
     "timestamp": 1742827095114,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "f73a5c35-c15d-49bb-8a33-a7f017159499",
    "outputId": "9b0007a7-7384-4f32-b588-4c00a3bba271"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "model = Model()\n",
    "# print(model)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = -1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# change learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train_samples = 0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs = model(features)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_predicted = outputs.argmax(-1)\n",
    "        train_correct += (train_predicted == labels).sum().item()\n",
    "        total_train_samples += labels.size(0)\n",
    "\n",
    "    # Learning rate update\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = 100. * train_correct / total_train_samples\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features = features.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = model(features)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            predicted = outputs.argmax(-1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = 100. * correct / total\n",
    "\n",
    "    # Checkpoint\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "\n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        torch.save(model.state_dict(), 'model_classification.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train loss: {avg_train_loss:.4f}, Train acc: {train_accuracy:.4f}%, Val loss: {avg_val_loss:.4f}, Val acc: {val_accuracy:.4f}%, Best Val loss: {best_val_loss:.4f} Best Val acc: {best_val_acc:.2f}%')\n",
    "\n",
    "    # Store performance\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ade706a0b119405abff683ccd2fb943d",
      "1cd8f969196d4b80808c25896581c577",
      "b965be11e38b47e0b0f58cca043bf0ec",
      "965501ad4532438e97a6c7b58bef3185",
      "7c9cce91b36e45c08268f80cef5c30fe",
      "6b0cf8d2a7dc4cd394faca001d2021d6",
      "d46f2701c6284a0ab921b8744fa5cb5d",
      "a28c3442fff24a9ea9cf07f95a84bc7f",
      "61b82834380645a7a055554139b2a3c1",
      "46bab0ff852a46e195620bddca5a083f",
      "f6b92169b4354c339682178193d81a47",
      "061cd1dda5054cb59fc12665c7e5eaab",
      "eb03ac1bb5e8482c9cbe0983dd065dc9",
      "33d0c1b3ced643349b645d1b478f26b0",
      "54836381ea0b4c958bc866e5781973de",
      "082668d378524e1d92ee0162b8502ba0",
      "56120d4cc1cb47a1935163d0bb149f2f",
      "a04c8b981f85463780e6fc405816531f",
      "7fa72e6c1fa94409b1f165e62da3faeb",
      "4ac57d980d1d4f2ba9909e145139a78f",
      "fedb81adceda4b349df76ab28ee7e497",
      "1a5904479c1f4897bb4599c4efd87f9e",
      "56aed83ef44a4b0385251ef007c21bf0",
      "3afcdc83400342bda263bfb7ca20ae48",
      "3478965be9344750935c4949b8e0fa0e",
      "f5b1482c70794469b6318cf2bfe25f63",
      "e5a55e290b4a4bbe802728e4c286eec0",
      "f6f367fc16ed4fe08ad77bebbd4881d8",
      "41844ee0d3294cb5a3a4c175f0ca0f0c",
      "1c24dab667ec43f09dd18b4047a5c55f",
      "01590ccf005f4ba0982e7e58c82007ea",
      "514b78421f2840af86b6dcd12a7b9d46",
      "2b13df8556c749fab606fec3b8ee504f"
     ]
    },
    "executionInfo": {
     "elapsed": 4750,
     "status": "ok",
     "timestamp": 1742829823822,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "4TeduMlOtkA_",
    "outputId": "402c859e-eb1f-4a61-ae46-6299cdf7311b"
   },
   "outputs": [],
   "source": [
    "# 超參數-learning rate 0.1 0.01 0.001\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "epochs = 100\n",
    "learning_rates = [0.001, 0.01, 0.1]  # 測試不同學習率\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f'\\nTraining with learning rate: {lr}')\n",
    "\n",
    "    # 初始化模型 & 優化器\n",
    "    model = Model().cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    lr_scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = -1\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        train_correct = 0\n",
    "        total_train_samples = 0\n",
    "\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.cuda(), labels.cuda()\n",
    "\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_predicted = outputs.argmax(-1)\n",
    "            train_correct += (train_predicted == labels).sum().item()\n",
    "            total_train_samples += labels.size(0)\n",
    "\n",
    "        # Learning rate update\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_accuracy = 100. * train_correct / total_train_samples\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        total_val_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.cuda(), labels.cuda()\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "                predicted = outputs.argmax(-1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                total_val_samples += labels.size(0)\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = 100. * val_correct / total_val_samples\n",
    "\n",
    "        # Checkpoint\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            torch.save(model.state_dict(), f'model_lr_{lr}.pth')\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train loss: {avg_train_loss:.4f}, Train acc: {train_accuracy:.2f}%, '\n",
    "              f'Val loss: {avg_val_loss:.4f}, Val acc: {val_accuracy:.2f}%')\n",
    "\n",
    "    # 測試集評估\n",
    "    model.eval()\n",
    "    total_test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    total_test_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.cuda(), labels.cuda()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_test_loss += loss.item()\n",
    "            predicted = outputs.argmax(-1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            total_test_samples += labels.size(0)\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    test_accuracy = 100. * test_correct / total_test_samples\n",
    "\n",
    "    # 存入結果\n",
    "    results.append([lr, avg_train_loss, avg_val_loss, avg_test_loss, train_accuracy, val_accuracy, test_accuracy])\n",
    "\n",
    "# 轉成 DataFrame，輸出表格\n",
    "columns = [\"Learning Rate\", \"Train Loss\", \"Validation Loss\", \"Test Loss\", \"Train Accuracy\", \"Validation Accuracy\", \"Test Accuracy\"]\n",
    "df = pd.DataFrame(results, columns=columns)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 854,
     "status": "ok",
     "timestamp": 1742831323745,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "7nw6b7g_1jbI",
    "outputId": "45547b56-0b98-43fb-8789-a24d12688107"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Draw plots for Train and Validation Losses\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Train Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.lineplot(data=df, x='Learning Rate', y='Train Loss', marker='o', hue='Learning Rate')\n",
    "plt.title(\"Train Loss vs Learning Rate\")\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "\n",
    "# Plot Validation Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.lineplot(data=df, x='Learning Rate', y='Validation Loss', marker='o', hue='Learning Rate')\n",
    "plt.title(\"Validation Loss vs Learning Rate\")\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Draw plots for Train and Validation Accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Train Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.lineplot(data=df, x='Learning Rate', y='Train Accuracy', marker='o', hue='Learning Rate')\n",
    "plt.title(\"Train Accuracy vs Learning Rate\")\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Train Accuracy\")\n",
    "\n",
    "# Plot Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.lineplot(data=df, x='Learning Rate', y='Validation Accuracy', marker='o', hue='Learning Rate')\n",
    "plt.title(\"Validation Accuracy vs Learning Rate\")\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5b9ca881678b4235872da26132f16fae",
      "563dccec881e4f42a3bb376f38f905ee",
      "036c7a78bc3140a28ac8885c1475f98c",
      "c7d654ea00f8489983de136920cabaf4",
      "2e464225cd1640f781f0a1070ea7ef0d",
      "669de5c227ca49a09622088379819265",
      "21e31e028e09406aba9081a5a72ead26",
      "3bad7e533b784ff0a103b9e44eadc3c4",
      "436c530df10443c1a58e3b85b25ddc8d",
      "23a11d13879f4dbf85c18be20178e396",
      "5fdccbd9b7a94691a2f6fb6955f18f7c",
      "cf56f9cae74b47a4ad3b516a4b3fa92d",
      "41ad838395c54d51b0802157d6641803",
      "e70a9cdc3e4346fc8318151006f8c616",
      "f9954057b84847f9957f89c53148c024",
      "8bb4c37bd076461cbf1028c098937721",
      "76ea98e5b0304d1e90d2e4679eab44a8",
      "e7655082e8dc4cb28c0ede44a86b636b",
      "826a77d9e9364a9fbed7a3d662c470db",
      "7a49caab5b53499789e730199b984d34",
      "1bc0f18a049d49e48e95289ecd50a4c8",
      "5caf44f06f7a473386f3c235b52ab83c",
      "335df904acac40e7841641f99474481d",
      "27a8a94a2d6748e98de86571a68ebae7",
      "b6f225b135264da0823897a948682381",
      "a154b8ae03ff4a39badc65c1b0231ab8",
      "0415f73b83b749509eed80467d0c8ae8",
      "43d1fce85de74a7f9c02ced4bf818094",
      "865a57dda77c4e2ab68ada18f327c88a",
      "ff3a86b93ef14007b702f7ec62a426f8",
      "f437bed10fe245779a3588daf51c31d8",
      "f39a9aa89c9b4e7989c2130a183e74d4",
      "1e09a2c15669487f8e8aacd72364e4ed"
     ]
    },
    "executionInfo": {
     "elapsed": 5006,
     "status": "ok",
     "timestamp": 1742831318321,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "Zio2sdKKv6dS",
    "outputId": "600debb7-c24e-4c22-b9ba-d5d45f1a990d"
   },
   "outputs": [],
   "source": [
    "#超參數-epoch 50 100 150\n",
    "epochs_list = [50, 100, 150]  # 測試不同的 epoch 值\n",
    "learning_rates = [0.001]  # 仍然測試不同學習率\n",
    "results = []\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    for lr in learning_rates:\n",
    "        print(f'\\\\nTraining with Learning Rate: {lr}, Epochs: {epochs}')\n",
    "\n",
    "        # 初始化模型 & 優化器\n",
    "        model = Model().cuda()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        lr_scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        best_val_acc = -1\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            # Training\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            train_correct = 0\n",
    "            total_train_samples = 0\n",
    "\n",
    "            for features, labels in train_loader:\n",
    "                features, labels = features.cuda(), labels.cuda()\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_predicted = outputs.argmax(-1)\n",
    "                train_correct += (train_predicted == labels).sum().item()\n",
    "                total_train_samples += labels.size(0)\n",
    "\n",
    "            # Learning rate update\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            avg_train_loss = total_loss / len(train_loader)\n",
    "            train_accuracy = 100. * train_correct / total_train_samples\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            total_val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            total_val_samples = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for features, labels in val_loader:\n",
    "                    features, labels = features.cuda(), labels.cuda()\n",
    "                    outputs = model(features)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    total_val_loss += loss.item()\n",
    "                    predicted = outputs.argmax(-1)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    total_val_samples += labels.size(0)\n",
    "\n",
    "            avg_val_loss = total_val_loss / len(val_loader)\n",
    "            val_accuracy = 100. * val_correct / total_val_samples\n",
    "\n",
    "            # Checkpoint\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "\n",
    "            if val_accuracy > best_val_acc:\n",
    "                best_val_acc = val_accuracy\n",
    "                torch.save(model.state_dict(), f'model_lr_{lr}_epochs_{epochs}.pth')\n",
    "\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Train loss: {avg_train_loss:.4f}, Train acc: {train_accuracy:.2f}%, '\n",
    "                  f'Val loss: {avg_val_loss:.4f}, Val acc: {val_accuracy:.2f}%')\n",
    "\n",
    "        # 測試集評估\n",
    "        model.eval()\n",
    "        total_test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        total_test_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for features, labels in test_loader:\n",
    "                features, labels = features.cuda(), labels.cuda()\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_test_loss += loss.item()\n",
    "                predicted = outputs.argmax(-1)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                total_test_samples += labels.size(0)\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(test_loader)\n",
    "        test_accuracy = 100. * test_correct / total_test_samples\n",
    "\n",
    "        # 存入結果\n",
    "        results.append([lr, epochs, avg_train_loss, avg_val_loss, avg_test_loss, train_accuracy, val_accuracy, test_accuracy])\n",
    "\n",
    "# 轉成 DataFrame，輸出表格\n",
    "columns = [\"Learning Rate\", \"Epochs\", \"Train Loss\", \"Validation Loss\", \"Test Loss\", \"Train Accuracy\", \"Validation Accuracy\", \"Test Accuracy\"]\n",
    "df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# 調整 Accuracy 格式為 xx.xx%\n",
    "df[\"Train Accuracy\"] = df[\"Train Accuracy\"].map(lambda x: f\"{x:.2f}%\")\n",
    "df[\"Validation Accuracy\"] = df[\"Validation Accuracy\"].map(lambda x: f\"{x:.2f}%\")\n",
    "df[\"Test Accuracy\"] = df[\"Test Accuracy\"].map(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "error",
     "timestamp": 1742831444815,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "BLk6EoMP2Spw",
    "outputId": "8b7e9cb9-75a6-409e-f5d1-86f2c1582653"
   },
   "outputs": [],
   "source": [
    "# 畫出損失和準確度曲線\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 損失曲線\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(epochs * len(epochs_list)), train_losses, label='Train Loss')\n",
    "plt.plot(range(epochs * len(epochs_list)), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train vs Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 準確度曲線\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(epochs * len(epochs_list)), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(epochs * len(epochs_list)), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train vs Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "a7984c6e-6652-4160-b572-07d48bc93a3f"
   },
   "source": [
    "#### Visualizing the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 448,
     "status": "ok",
     "timestamp": 1742827212691,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "5559d850-1fb5-4b04-b6ca-60c5b309f34e",
    "outputId": "9cadf878-5f0c-4b37-b881-0941d6c36c22"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "ax[0].plot(train_accuracies)\n",
    "ax[0].plot(val_accuracies)\n",
    "ax[0].set_title('Model Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend(['Train', 'Val'])\n",
    "\n",
    "# Plotting training and validation loss\n",
    "ax[1].plot(train_losses)\n",
    "ax[1].plot(val_losses)\n",
    "ax[1].set_title('Model Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend(['Train', 'Val'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1742831113727,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "1YV3Adwu1E5k",
    "outputId": "ba309452-2c1c-4c68-a297-625aba02344d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "ax[0].plot(train_accuracies)\n",
    "ax[0].plot(val_accuracies)\n",
    "ax[0].set_title('Model Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend(['Train', 'Val'])\n",
    "\n",
    "# Plotting training and validation loss\n",
    "ax[1].plot(train_losses)\n",
    "ax[1].plot(val_losses)\n",
    "ax[1].set_title('Model Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend(['Train', 'Val'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "89c7e51b-8ab6-4aa2-877d-39b6daf55c20"
   },
   "source": [
    "## D. Evaluating Your Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1742827229874,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "f49735d7-466f-4037-8078-172f03dffd8d",
    "outputId": "7f3e8c80-5180-43b4-82a6-22015f8cee2b"
   },
   "outputs": [],
   "source": [
    "# read test file\n",
    "test_data = pd.read_csv('/content/drive/MyDrive/深度學習/heart_dataset_test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1742827233873,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "21ae9d85-0dc2-4db0-a7c7-807c6b6c514f",
    "outputId": "d194cf72-3c3a-4a29-ece9-024988e5eec3"
   },
   "outputs": [],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742827234468,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "5ff2812b-a5a5-4ea9-86be-ae2143cb2ba7",
    "outputId": "2fc25faa-e319-4812-90f0-c2d8817fa0de"
   },
   "outputs": [],
   "source": [
    "test_data = test_data.values\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742827234846,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "14d4be20-f64f-421d-8971-e1e47873aef8"
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "x_test = torch.from_numpy(test_data[:, :13]).float()\n",
    "y_test = torch.from_numpy(test_data[:, 13]).long()\n",
    "\n",
    "# Create datasets\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "# Create dataloaders\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1742829538033,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "4bcf8580-42ee-4ee7-ad15-9f080cc57a33",
    "outputId": "1d862131-5ed7-40ca-ddaa-b15a21f52cf0"
   },
   "outputs": [],
   "source": [
    "# Load the trained weights\n",
    "model.load_state_dict(torch.load('model_classification.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs = model(features)\n",
    "\n",
    "        predicted = outputs.argmax(-1)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "print(f'Test accuracy is {100. * test_correct / test_total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742829539038,
     "user": {
      "displayName": "YUNSIOU HUANG",
      "userId": "04304133596875458473"
     },
     "user_tz": -480
    },
    "id": "Swf6HvPQmSex"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
